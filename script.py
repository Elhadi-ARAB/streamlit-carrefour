
import streamlit as st
import pandas as pd
import os
import re
import time
import urllib.parse
import unicodedata






# === Listes de mots-cl√©s pour le mapping ===
video_keywords = [
    "In-Stream-Classic", "In-Stream-Trueview", "Video-Dynamic-Creative", "Connected-TV",
    "Synchro-TV", "In-Stream-trueview-for-reach", "In-Stream-trueview-for-action",
    "In-Stream-trueview-for-lead", "In-Stream-non-skippable", "In-Stream-bumper",
    "In-Stream-catch-up", "Out-Stream-inread", "Out-Stream-pave-video", "Video-Ad-Serving-Template"
]

display_keywords = [
    "Display-IAB", "Display-Native", "Redirect", "Display-Social", "Display-Dynamic-Creative",
    "Digital-Out-of-Home", "Emailing", "Display-panorama", "Display-scratch", "Display-slider",
    "Display-inread", "Display-swipe-to-site", "Display-habillage", "Display-habillage-video",
    "Display-habillage-sliding", "Display-habillage-swapping", "Pixel+Click-Command"
]


ALLOWED_PLATFORMS = ["DV360", "Ogury", "Seedtag_FR", "Spotify_FRA", "M6+"]


def map_tracking_type(value):
    val = str(value).strip()
    if val in video_keywords:
        return "VIDEO"
    elif val == "Stream-Audio":
        return "AUDIO"
    elif val in display_keywords:
        return "DISPLAY"
    else:
        print(f"‚ö†Ô∏è Format Type non reconnu: {val}. Contactez l'√©quipe Data.")
        return "OTHER"

    
    
    

_SPECIALS = set(list('!"#$%&\'()*+,/:;<=?>@[\\]^{|}~%'))  # caract√®res √† remplacer par "_"
_UTM_KEYS = {"utm_source", "utm_medium", "utm_campaign", "utm_term", "utm_content"}

def _strip_accents(s: str) -> str:
    """Supprime les accents de mani√®re g√©n√©rique (√©‚Üíe, √±‚Üín, etc.)."""
    nfkd = unicodedata.normalize("NFKD", s)
    return "".join(ch for ch in nfkd if not unicodedata.combining(ch))

def _sanitize_text_for_utm(s: str) -> str:
    if s is None:
        return s
    s = str(s)
    s = _strip_accents(s)
    # üîÅ remplace espaces ET caract√®res sp√©ciaux par "_"
    s = "".join("_" if (ch in _SPECIALS or ch.isspace()) else ch for ch in s)
    s = re.sub(r"_+", "_", s).strip("_")
    return s

def _idna_hostname(host: str) -> str:
    """Normalise le nom d‚Äôh√¥te (lowercase + IDNA)."""
    if not host:
        return host
    host = host.strip().lower()
    try:
        return host.encode("idna").decode("ascii")
    except Exception:
        return host

def _normalize_path(path: str) -> str:
    """
    Normalise le chemin :
    - √©vite le double-encodage des % d√©j√† pr√©sents
    - encode les caract√®res non s√ªrs selon RFC 3986
    """
    if path is None or path == "":
        return "/"
    # on ‚Äúd√©code‚Äù une fois puis on r√©-encode proprement
    unquoted = urllib.parse.unquote(path)
    # safe: on garde / % et les caract√®res r√©serv√©s usuels en path
    return urllib.parse.quote(unquoted, safe="/%:@-._~!$&'()*+,;=")

def _encode_q_value(v: str) -> str:
    """Encode standard pour les valeurs de query (hors UTM)."""
    if v is None:
        return ""
    # on √©vite de r√©-encoder les % des s√©quences %XX d√©j√† valides
    return urllib.parse.quote_plus(v, safe="%:@-._~!$'()*,")

def normalize_url_preserving_utm(url: str) -> str:
    """
    1) Normalise sch√©ma/h√¥te/chemin.
    2) Re-encode proprement TOUTES les paires query, SAUF les valeurs UTM.
       - UTM : on ne modifie pas le texte, on √©chappe seulement & et = pour ne pas casser la query.
       - Non-UTM : encodage standard (quote_plus).
    """
    if not url or not isinstance(url, str):
        return url

    u = url.strip()
    if u.startswith("www."):
        u = "https://" + u  # ajout d‚Äôun sch√©ma par d√©faut si n√©cessaire

    parts = urllib.parse.urlsplit(u)

    scheme = (parts.scheme or "https").lower()
    netloc = _idna_hostname(parts.netloc)
    path = _normalize_path(parts.path)

    # Parse query, en conservant l‚Äôordre et les valeurs vides
    pairs = urllib.parse.parse_qsl(parts.query, keep_blank_values=True)

    new_pairs = []
    for k, v in pairs:
        k_enc = urllib.parse.quote(k, safe="%:@-._~")  # cl√©s encod√©es proprement

        if k.lower() in _UTM_KEYS:
            v_safe = (v or "")
            v_safe = v_safe.replace("&", "%26").replace("=", "%3D")
            if v_safe == "":
                new_pairs.append(f"{k_enc}")            # ‚ùó pas de "=" si vide
            else:
                new_pairs.append(f"{k_enc}={v_safe}")
        else:
            v_enc = _encode_q_value(v or "")
            if v_enc == "":
                new_pairs.append(f"{k_enc}")            # ‚ùó pas de "=" si vide
            else:
                new_pairs.append(f"{k_enc}={v_enc}")


    new_query = "&".join(new_pairs)

    # Fragment : on l‚Äôencode proprement sans double-encodage
    fragment = urllib.parse.quote(urllib.parse.unquote(parts.fragment or ""), safe="%:@-._~!$&'()*+,;=/")

    return urllib.parse.urlunsplit((scheme, netloc, path, new_query, fragment))

def sanitize_url_utm_values(url: str) -> str:
    """
    2) Ne modifie QUE les valeurs des param√®tres UTM.
       Conserve sch√©ma, h√¥te, chemin et autres param√®tres intacts.
    """
    if not url or not isinstance(url, str):
        return url
    try:
        parts = urllib.parse.urlsplit(url)
        pairs = urllib.parse.parse_qsl(parts.query, keep_blank_values=True)

        new_pairs = []
        for k, v in pairs:
            k_enc = urllib.parse.quote(k, safe="%:@-._~")
            if k.lower() in _UTM_KEYS:
                raw = _sanitize_text_for_utm(v)
                raw = (raw or "").replace("&", "%26").replace("=", "%3D")
                if raw == "":
                    new_pairs.append(f"{k_enc}")            # ‚ùó pas de "=" si vide
                else:
                    new_pairs.append(f"{k_enc}={raw}")
            else:
                if v == "":
                    new_pairs.append(f"{k_enc}")            # ‚ùó pas de "=" si vide
                else:
                    new_pairs.append(f"{k_enc}={v}")

        new_query = "&".join(new_pairs)
        return urllib.parse.urlunsplit((parts.scheme, parts.netloc, parts.path, new_query, parts.fragment))
    except Exception:
        return url


def generate_files(df, output_folder="exports_cm"):
    os.makedirs(output_folder, exist_ok=True)
    grouped = df.groupby(["Nom de la campagne*", "D√©but  JJ/MM/AAAA", "Fin  JJ/MM/AAAA"])
    filepaths = []
    ignored_platforms = []   # plateformes non autoris√©es
    unknown_tracking = []    # tracking type non reconnus

    for (campagne, start, end), group in grouped:
        if pd.isna(campagne) or pd.isna(start) or pd.isna(end):
            continue

        header_data = {
            "Consultant_Email": "",
            "Campaign_Name": campagne,
            "Advertiser Name": "NEW Carrefour One - Havas",
            "Landing page": "https://www.carrefour.fr/",
            "Start_Date": start,
            "End_Date": end
        }

        rows = []
        for _, row in group.iterrows():
            if pd.isna(row["Format size (CM only)"]):
                continue

            # ‚ûú contr√¥le plateforme
            platform = str(row["Platform"]).strip()
            if platform not in ALLOWED_PLATFORMS:
                ignored_platforms.append((campagne, platform))
                continue

            # ‚ûú mapping sp√©cifique DV360
            if platform == "DV360":
                site_name = "DV360 - CRF Marketing - Agence 79"
            elif platform == "TF1":
                site_name = "TF1_FRA"
            elif platform == "SNCF":
                site_name = "Groupe Sncf"
            else:
                site_name = platform


            # ‚ûú contr√¥le Tracking Type
            raw_tracking = row.get("Tracking Type", "")
            tracking_type = map_tracking_type(raw_tracking)
            if tracking_type == "OTHER":
                unknown_tracking.append((campagne, str(raw_tracking).strip()))
                continue  # on n‚Äôinclut pas cette ligne dans l‚Äôexport

            original_url = row.get("URL de redirection track√©e")
            formatted_url = normalize_url_preserving_utm(original_url)
            safe_url = sanitize_url_utm_values(formatted_url)

            rows.append({
                "Site Name": site_name,
                "Type de Tracking": tracking_type,
                "Format": row["Format size (CM only)"],
                "Placement_Name": row["Placement CM = creative DV360"],
                "Creative_Name": row["Creative Name"],
                "Add_ClickTroughUrl": safe_url,
                "IMPRESSION_JAVASCRIPT_EVENT_TAG": row["XPLN script CM"]
            })

        if not rows:
            continue

        df_table = pd.DataFrame(rows)
        safe_name = str(campagne).replace(" ", "_").replace("/", "_")
        filename = f"CM_{safe_name}_carrefour.xlsx"
        filepath = os.path.join(output_folder, filename)

        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            for i, (key, val) in enumerate(header_data.items()):
                pd.DataFrame([[key, val]]).to_excel(writer, index=False, header=False, startrow=i, startcol=0)
            df_table.to_excel(writer, index=False, startrow=9)

        filepaths.append(filepath)

    # ‚ûú on renvoie les deux rapports d‚Äôerreurs
    return filepaths, ignored_platforms, unknown_tracking


# === Interface Streamlit ===

st.title("üìä G√©n√©rateur de fichiers Media Carrefour")

uploaded_file = st.file_uploader("D√©pose ici le fichier Excel de l'URL Builder", type=["xlsx"])

if uploaded_file is not None:
    try:
        df = pd.read_excel(uploaded_file, sheet_name="URL BUILDER", skiprows=1)
        df = df.dropna(how='all')
        df["D√©but  JJ/MM/AAAA"] = pd.to_datetime(df["D√©but  JJ/MM/AAAA"], errors='coerce')
        df["Fin  JJ/MM/AAAA"] = pd.to_datetime(df["Fin  JJ/MM/AAAA"], errors='coerce')
        df = df.dropna(subset=["Nom de la campagne*", "D√©but  JJ/MM/AAAA", "Fin  JJ/MM/AAAA", "Format size (CM only)"])

        st.success("‚úÖ Fichier charg√© avec succ√®s.")

        if st.button("üöÄ G√©n√©rer les fichiers"):
            with st.spinner("‚è≥ G√©n√©ration des fichiers en cours..."):
                start = time.time()
                paths, ignored_platforms, unknown_tracking = generate_files(df)
                duration = round(time.time() - start, 2)

            has_error = False

            # ‚ö†Ô∏è Plateformes non autoris√©es
            if ignored_platforms:
                has_error = True
                st.error("‚ùå Des lignes ont √©t√© ignor√©es car la plateforme n‚Äôest pas autoris√©e :")
                for campagne, plat in ignored_platforms:
                    st.write(f"- Campagne **{campagne}** ‚Üí Plateforme non reconnue : **{plat}**")

            # ‚ö†Ô∏è Tracking Type non reconnu
            if unknown_tracking:
                has_error = True
                st.error("‚ùå Des lignes ont √©t√© ignor√©es car le 'Tracking Type' est non reconnu :")
                for campagne, trk in unknown_tracking:
                    st.write(f"- Campagne **{campagne}** ‚Üí Tracking Type non reconnu : **{trk}**")
                st.info("‚ÑπÔ∏è Valeurs accept√©es : v√©rifiez dans l‚Äôonglet Input A79 de l‚ÄôURL Builder si le Tracking Type y est bien renseign√©")

            if has_error:
                st.warning("üö´ Aucun fichier n‚Äôa √©t√© g√©n√©r√©. Corrigez le fichier source puis r√©essayez.")
            else:
                st.success(f"‚úÖ {len(paths)} fichiers g√©n√©r√©s en {duration} secondes.")
                st.info("‚ÑπÔ∏è N‚Äôoubliez pas d‚Äôintroduire votre adresse mail en colonne B (ligne Consultant_Email). Merci üôè")
                for p in paths:
                    with open(p, "rb") as f:
                        data = f.read()
                    st.download_button(label=f"T√©l√©charger {os.path.basename(p)}", data=data, file_name=os.path.basename(p))


    except Exception as e:
        st.error(f"‚ùå Erreur lors du traitement du fichier : {e}")

